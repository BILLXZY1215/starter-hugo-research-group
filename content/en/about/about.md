---
weight: 10

# Page title
title: |
  **A**ccessible & **P**ervasive User **EX**perience  <br>
  (APEX) Group

design:
  # Choose how many columns the section has. Valid values: '1' or '2'.
  columns: "1"
  # view: showcase
---

AI and computing technologies have been changing people’s lives at unprecedented speed. It is important to “get the right design” and “get the design right” when designing AI- and computing-powered systems that humans ultimately use so that everyone can benefit from computing.  

Led by [Prof. Mingming Fan](https://www.mingmingfan.com/), APEX group conducts research at the intersection of Human-Computer Interaction (HCI), AI and VR/AR/MR with three foci: 

- **Assistive Technology (AT):** to empower older adults and people with disabilities 

- **Human-AI Collaboration:** to understand human-AI collaboration dynamics via scientific studies and to create novel human-AI collaboration systems. 

- **VR/AR/MR:** to create novel VR/AR/MR interaction techniques and applications, for aging, accessibility and learning/education purposes.

Our group’s work has been published at top-tier venues of human-computer interaction (HCI). We have won Best Paper Honorable Mention Awards (4 times) and Best Paper Award from ACM CHI, Best Paper Honorable Mention Awards from UbiComp, Best Artifact Awad from ACM ASSETS, and Best Paper Honorable Mention Awards from Chinese CHI (2 times). 

Next, we present example projects to illustrate our research under each theme:

<li>Understanding <b>Accessibility Challenges</b> and Creating novel <b>Assistive Technology</b>
<ul>
  <li>Understand <i>Accessibility Challenges</i> for Older Adults
    <!-- <dt> -->
      <dd>e.g., Language reflects thought. Can we identify problems that older adults encounter when using technology through what they say and how they say it? (<a href="publications.html#OA-TA">CHI 2021</a>)</dd>
    <!-- </dt> -->
    <!-- <dt>
      <dd>e.g., How do older adults manage their banking needs in light of the increasngly popular mobile and digital banking services? (<a href="publications.html#OA-banking-survey">DIS 2021</a>)</dd>
    </dt> -->
    <!-- <dt> -->
      <dd>e.g., Older adults tend to rely on instructions to learn technologies. However, instructions are often difficult to use. How to design senior-friendly instructions? (<a href="publications.html#SeniorGuidelines">TACCESS (ASSETS 2018)</a>)</dd>
    <!-- </dt> -->

  </li>
  <li>Design Novel <i>Assistive Technologies</i> for Older Adults
    <dd>
      e.g., Trial-and-error is a common and effective way to learn new technology but older adults often face challenges using it. How do we design interactive guidance to help older adults learn digital technology with trial-and-error support? (<a href="publications.html#IMWUT22-OA-Interactive-Guidance">IMWUT(UbiComp 2022)</a>)
    </dd>
      <dd>e.g., Older adults often face memory issues. Can we leverage mobile and sensing technology to help older adults remember better? (<a href="publications.html#FMT">IMWUT (UbiComp 2019)</a>)</dd>
    </li>
  <li>Understand <i>Accessibility</i> Challenges for People with Disabilities
    <!-- <dt> -->
      <dd>e.g., Like sighted people, people with vision impairments (PVI) also need to fetch packages for items they shop online. What challenges do PVI experience?(<a href="publications.html#CHI22-KuaiDiGui">CHI 2022</a>)</dd>
    <!-- </dt> -->
    <!-- <dt>
      <dd>e.g., BLV people also livestream and hope to reach out to a broad audience. However, do the livestreaming platforms bias against them? (<a href="publications.html#CHI22-BLV-Livestreaming">CHI 2022</a>)</dd>
    </dt> -->
    <!-- <dt> -->
      <dd>e.g., How do people with disabiities perceive about accessibility and assistive technology use in China? (<a href="publications.html#AT-China">CHI 2021</a>)</dd>
    <!-- </dt> -->

  </li>

  <li>Design Novel <i>Assistive Technologies</i> for People with Disabilities
      <dd>e.g., People with motor impairments have difficulty using touch screens. What gestures do they want to create that involve above-the-neck body parts to interact with touchscreen devices? (<a href="publications.html#CHI22-UserDefinedGestures">CHI 2022</a>)</dd>
      <dd>e.g., How to enable people with motor impairments interact with touchscreen devices with eyelid gestures? (<a href="publications.html#CACM-EyelidGestures">CACM 2022</a>, <a href="publications.html#EyelidGestures4ASSETS">ASSETS 2020</a>)</dd>
      <dd>e.g., How to design an easy-to-learn gesture-based text-entry method for people with visual impairments? (<a href="publications.html#BrailleSketch">ASSETS 2017</a>)</dd>

  </li>
</ul>
</li>

<li>Exploring Novel <b>Computational User Experience (UX) Methods</b> to Better Detect, Understand, and Resolve User Experience (UX) Problems
<ul>
<li>Design <i>Human-AI Collaborative UX Analysis Tools and Methods</i>
  <dd>e.g., How do different ways of collaboration between AI and UX evaluators affect their performance and perception of AI? (<a href="publications.html#HAI-UX-Evaluation">CSCW 2022</a>)</dd>
  <dd>e.g., How to design an AI-Assisted interactive system to help UX evaluators analyze usabilty test videos? (<a href="publications.html#VisTA">TVCG (VIS 2019)</a>) </dd>
  <dd>e.g., How to design an AI-Assisted interactive system to help UX evaluators collaborate during their analysis? (<a href="publications.html#CoUX">TVCG (VIS 2021)</a>) </dd>
</li>
<li>Build <i>AI</i> models to Detect UX Problems Automatically
  <dd>e.g., How to build AI models to identify UX problems automatically? (<a href="publications.html#UXAutomaticDetection">TiiS 2020</a>) </dd>
</li>
<li>Understand How Humans Collaborate to Draw Inspirations For Human-AI Collaboration
  <dd>e.g., How do UX practitioners collaborate in industry? (<a href="publications.html#CHI22-UX-Survey">CHI 2022</a>)</dd>
</li>
<li>Understand <i>UX Problems</i> Via People' Subtle Behavioral Signals
    <dd>e.g., What are subtle verbalization and speech patterns indicating UX problems in think-aloud usability testing? (<a href="publications.html#OA-UX">CHI 2021</a>, <a href="publications.html#TOCHI19">TOCHI (CHI 2020)</a>)</dd>
</li>
</ul>
</li>

<li>Making <b>VR/AR/Metaverse</b> More Accessible by Creating <i>Multi-Sensory Experiences</i> and <i>Novel Interaction Techniques</i>.
<ul>
    <li>Create <i>Multi-Sensory Experience</i>
        <dd>e.g., How to create <b>pain sensation</b> to enhance VR users' immersive experiences? (<a href="publications.html#VR-pain">IMWUT (UbiComp 2021)</a>)</dd>
        <dd>e.g., How to create <b>wetness illusion</b> to enhance VR users' immersive experiences? (<a href="publications.html#mouille">CHI 2020</a>)</dd>
    </li>
    <li>Design Novel <i>Interaction Techniques</i>
      <dd>e.g., How to help VR users select occluded and distant objects more easily with intuitive interaction? (<a href="publications.html#VR-mirror">CHI 2021</a>)</dd>
    </li>
    <li>Design Novel Sensing Technology (e.g., context-aware sensing and applications)
      <dd>e.g., How to unobstrustively monitor the amount of remaining content in a container? (<a href="publications.html#SoQr">UbiComp 2015</a>)</dd>
      <dd>e.g., How to make a wearable device smart enough to understand the type of physical space that its wearer is in? (<a href="publications.html#PublicRestroom">ISWC 2014</a>)</dd>
    </li>

  </ul>
</li>
