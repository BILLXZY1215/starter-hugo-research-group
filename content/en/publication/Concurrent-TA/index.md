---
title: Concurrent Think-Aloud Verbalizations and Usability Problems
authors:
  - Mingming Fan
  - Jinglan Lin
  - Christina Chung
  - Khai N. Truong
author_notes:
  - 
  - 
  -
  -
  -
  -
date: '2019-11-11T00:00:00Z'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2017-01-01T00:00:00Z'

# Publication type: 
# 0 = Uncategorized; 1 = Accessibility & Aging; 2 = VR/AR/Metaverse; 3 = Human-AI Collaboration; 4 = UX Methodology; 5 = Social Computing; 6 = Sensing;  7 = Thesis; 8 = Patent
publication_types: ['4']

# Publication name and optional abbreviated publication name.
publication: ACM Transactions on Computer-Human Interaction. 26 (5), Article 8, 35 pages, 2019
publication_short: TOCHI (CHI 2020)

abstract: The concurrent think-aloud protocol—in which participants verbalize their thoughts when performing tasks - is a widely employed approach in usability testing. Despite its value, analyzing think-aloud sessions can be onerous because it often entails assessing all of a user’s verbalizations. This has motivated previous research on developing categories to segment verbalizations into manageable units of analysis. However, the way in which a category might relate to usability problems is currently unclear. In this research, we sought to address this gap in our understanding. We also studied how speech features might relate to usability problems. Through two studies, this research demonstrates that certain patterns of verbalizations are more telling of usability problems than others and that these patterns are robust to different types of test products (i.e., physical devices and digital systems), access to different types of information (i.e., video and audio modality), and the presence or absence of a visualization of verbalizations. The implication is that the verbalization and speech patterns can potentially reduce the time and effort required for analysis by enabling evaluators to focus more on the important aspects of a user’s verbalizations. The patterns could also potentially be used to inform the design of systems to automatically detect when in the recorded think-aloud sessions users experience problems.

# Summary. An optional shortened abstract.
summary:

keywords: Concurrent think-aloud, usability testing, verbalization, verbalization categories, speech features, silence, verbal fillers, sentiment, speech rate, loudness, pitch, usability problems

tags:
  - Concurrent think-aloud
  - usability testing
  - verbalization
  - verbalization categories
  - speech features
  - silence
  - verbal fillers
  - sentiment
  - speech rate
  - loudness
  - pitch
  - usability problems
featured: false

links:
  # - name: Custom Link
  #   url: http://example.org
url_pdf: 'https://www.mingmingfan.com/papers/TOCHI-2019-Fan.pdf'
# url_code: 'https://github.com/tjusenchen/Xbot'
# url_dataset: '#'
# url_poster: '#'
# url_project: ''
# url_slides: ''
# url_source: 'https://sites.google.com/view/mobile-accessibility/'
# url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
# projects:
#   - internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
# slides:
---

<!-- {{< youtube f9lO9tin4tw >}} -->


